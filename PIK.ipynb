{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wisp\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 43.42 MB\n",
      "Memory usage after optimization is: 23.73 MB\n",
      "Decreased by 45.3%\n",
      "Flats df shape: (1040, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def get_prices():\n",
    "    prices = reduce_mem_usage(pd.read_csv('./input/price.csv',\n",
    "                                         encoding='cp1251',\n",
    "                                         parse_dates=['datefrom','dateto']))\n",
    "    prices.drop(['date_salestart'], axis = 1, inplace = True)\n",
    "    # prices[\"datefrom_week\"] = prices['datefrom'].dt.week\n",
    "    prices[\"datefrom_month\"] = prices['datefrom'].dt.month\n",
    "    # prices[\"dateto_week\"] = prices['dateto'].dt.week\n",
    "    prices[\"dateto_month\"] = prices['dateto'].dt.month\n",
    "    prices[\"have_price\"] = prices['pricem2'].apply(lambda x: 1 if x > 50000 else 0)\n",
    "    prices[\"not_saled\"] = prices['dateto'].apply(lambda x: 1 if x == '2100-01-01 00:00:00' else 0)\n",
    "    prices['sales_duration'] = ((prices['dateto'] - prices['datefrom'])/30).dt.days\n",
    "    prices[\"sales_duration\"] = prices['sales_duration'].apply(lambda x: x if x > 900 else 0)\n",
    "\n",
    "    # unique_df = prices.nunique()\n",
    "    # dummy_features = list(unique_df[unique_df <= 12].index)\n",
    "    # prices = pd.get_dummies(prices, columns=dummy_features, dummy_na=True)\n",
    "    # del unique_df\n",
    "    aggregations = {}\n",
    "    aggregations = {\n",
    "                'pricem2': ['min','max','mean','count'],\n",
    "#                 'datefrom_month': ['mean'],\n",
    "#                 'dateto_month': ['mean'],\n",
    "                'have_price': ['mean', 'sum'],\n",
    "                'not_saled': ['mean', 'sum'],\n",
    "                'sales_duration': ['min', 'mean', 'max'],\n",
    "            }\n",
    "\n",
    "    # for cat in dummy_features:\n",
    "    #         aggregations[cat] = ['mean', 'min', 'max']\n",
    "\n",
    "    prices_agg = prices.groupby('id_flatwork').agg(aggregations)\n",
    "    prices_agg.columns = pd.Index(['PRICES_' + e[0] + \"_\" + e[1].upper() for e in prices_agg.columns.tolist()])\n",
    "    return prices_agg\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if (col_type != object) & (col_type != 'datetime64[ns]'):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category = True, keep_columns = None, max_num_of_unique_items = 31):\n",
    "    original_columns = list(df.columns)\n",
    "    if keep_columns is None:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    else:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object' and col not in keep_columns]\n",
    "    for col in categorical_columns:\n",
    "        if len(df[col].unique()) > max_num_of_unique_items :\n",
    "            categorical_columns = list(set(categorical_columns) - set([col]))\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "def get_flats(df):\n",
    "    flats = reduce_mem_usage(pd.read_csv('./input/flat.csv',\n",
    "                                         encoding='cp1251',\n",
    "                                         parse_dates=['date_salestart','date_settle','sale']))\n",
    "\n",
    "    # flats[\"date_salestart_weekday\"] = flats['date_salestart'].dt.weekday\n",
    "    flats[\"date_salestart_week\"] = flats['date_salestart'].dt.week\n",
    "    # flats[\"date_salestart_day\"] = flats['date_salestart'].dt.day\n",
    "    flats[\"date_salestart_month\"] = flats['date_salestart'].dt.month\n",
    "\n",
    "    # flats[\"date_settle_weekday\"] = flats['date_settle'].dt.weekday\n",
    "    flats[\"date_settle_week\"] = flats['date_settle'].dt.week\n",
    "    # flats[\"date_settle_day\"] = flats['date_settle'].dt.day\n",
    "    flats[\"date_settle_month\"] = flats['date_settle'].dt.month\n",
    "    flats['time_before_settle'] = ((flats['date_settle'] - flats['date_salestart'])/30).dt.days\n",
    "    \n",
    "    \n",
    "    flats['new_index_spalen'] = flats['id_bulk'] + '-' + flats['spalen'].astype(int).astype(str)\n",
    "   \n",
    "    aggregations = {\n",
    "            'stage_number': ['max', 'mean'],\n",
    "            'spalen': ['count','sum'],\n",
    "            'square': ['sum', 'mean'],\n",
    "#             'date_salestart_week': ['min','max','mean'],\n",
    "#             'date_salestart_month': ['min','max','mean'],\n",
    "#             'date_settle_week': ['min','max','mean'],\n",
    "#             'date_settle_month': ['min','max','mean'],\n",
    "            'time_before_settle': ['min','max','mean'],\n",
    "        }\n",
    "   \n",
    "    flats_agg = flats.groupby(['new_index_spalen']).agg(aggregations)\n",
    "    flats_agg.columns = pd.Index(['FLATS_sp_' + e[0] + \"_\" + e[1].upper() for e in flats_agg.columns.tolist()])\n",
    "    \n",
    "    discard_columns = [\"id_bulk\",\n",
    "    \"section\",\n",
    "    \"date_settle\",\n",
    "    \"date_salestart\",\n",
    "    \"id_gk\",\n",
    "    \"id_flatwork\",\n",
    "    \"Класс объекта\",\n",
    "    \"Количество помещений\",\n",
    "    \"Огорожена территория\",\n",
    "    \"Площадь земельного участка\",\n",
    "    \"Входные группы\",\n",
    "    \"Детский сад\",\n",
    "    \"Школа\",\n",
    "    \"Поликлиника\",\n",
    "    \"ФОК\",\n",
    "    \"Спортивная площадка\",\n",
    "    \"Автомойка\",\n",
    "    \"Кладовые\",\n",
    "    \"Колясочные\",\n",
    "    \"Кондиционирование\",\n",
    "    \"Вентлияция\",\n",
    "    \"Лифт\",\n",
    "    \"Система мусоротведения\",\n",
    "    \"Видеонаблюдение\",\n",
    "    \"Подземная парковка\",\n",
    "    \"Двор без машин\",\n",
    "    \"Машиномест\",\n",
    "    \"Площадь пром. зоны в радиусе 500 м\",\n",
    "    \"Площадь зеленой зоны в радиусе 500 м\",\n",
    "    \"До Кремля\",\n",
    "    \"До ТТК(км)\",\n",
    "    \"До Садового(км)\",\n",
    "    \"До большой дороги на машине(км)\",\n",
    "    \"До удобной авторазвязки на машине(км)\",\n",
    "    \"До метро пешком(км)\",\n",
    "    \"До промки(км)\",\n",
    "    \"До парка(км)\",\n",
    "    \"До парка пешком(км)\",\n",
    "    \"Станций метро от кольца\",\n",
    "    \"Площадь двора\",\n",
    "    \"vid\",\n",
    "    \"sale\",\n",
    "    \"plan_size\",\n",
    "    ]\n",
    "    feats = [f for f in flats_agg.columns.tolist() if f not in discard_columns]\n",
    "\n",
    "    gc.collect()\n",
    "    return flats_agg[feats]\n",
    "\n",
    "def add_lags(df, feat, index='new_index_spalen', by_col='month_cnt', aggfunc=np.mean):\n",
    "    temp = pd.pivot_table(df, index=index, values=[feat], columns=by_col, aggfunc=aggfunc)\n",
    "#     temp = df.pivot(index=index, values=[feat], columns=by_col)\n",
    "    cols = [feat+'_'+by_col+'_{}'.format(j[1]) if j[1] != \"\" else j[0] for i, j in enumerate(temp.columns)]\n",
    "    temp.columns = cols\n",
    "    temp[feat+'_lag_1'] = 0\n",
    "    for row_idx in range(temp.shape[0]):\n",
    "        for idx in range(len(cols)):\n",
    "            value = temp.iloc[row_idx, -idx-2]\n",
    "            if not np.isnan(value) :\n",
    "                temp.iloc[row_idx, -1] = value\n",
    "                break\n",
    "    new_cols = [feat+'_lag_1']\n",
    "    return temp, new_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"./input/train.csv\", encoding='cp1251')\n",
    "df_test = pd.read_csv(\"./input/test.csv\", encoding='cp1251')\n",
    "df_add = df_train[['bulk_id', 'start_square', 'spalen',\n",
    "                   'Класс объекта', 'month','value','mean_sq']]\n",
    "df_add['mean_sq_spalen'] = df_add['mean_sq'] / (df_add['spalen']+1)\n",
    "\n",
    "df_train.drop(['start_square', 'plan_s', 'plan_m', 'plan_l', 'vid_0', 'vid_1', 'vid_2'], axis=1, inplace=True)\n",
    "df_test['value']=-1\n",
    "\n",
    "target = df_train['value'].copy()\n",
    "df = pd.concat([df_train, df_test[df_train.columns]])\n",
    "\n",
    "df['mean_sq_spalen'] = df['mean_sq'] / (df['spalen']+1)\n",
    "df['mean_sq*price'] = df['mean_sq']*df['price'] ## 220.94\n",
    "df['spalen*Площадь зеленой зоны в радиусе 500 м'] = df['spalen']*df['Площадь зеленой зоны в радиусе 500 м'] ## 220,04\n",
    "df['spalen*month_cnt'] = df['spalen']*df['month_cnt'] ## 219.77\n",
    "df['mean_sq*До удобной авторазвязки на машине(км)'] = df['mean_sq']*df['До удобной авторазвязки на машине(км)'] ## 219.78\n",
    "df['Станций метро от кольца*price'] = df['Станций метро от кольца']*df['price'] ## 219.19\n",
    "df['price-*-mean_sq*price'] = df['price']*df['mean_sq*price']\n",
    "df['price-*-Станций метро от кольца*price'] = df['price']*df['Станций метро от кольца*price']\n",
    "df['mean_sq*price-*-Станций метро от кольца*price'] = df['mean_sq*price']*df['Станций метро от кольца*price']\n",
    "\n",
    "df['new_index_spalen'] = df['bulk_id'] + '-' + df['spalen'].astype(str)\n",
    "\n",
    "col1 = 'Класс объекта'\n",
    "col2 = 'spalen'\n",
    "col3 = 'month'\n",
    "index_name = 'index_'+col1+'_'+col2+'_'+col3\n",
    "df[index_name] = df[col1] + '-' + df[col2].astype(str) + '-' + df[col3].astype(str)\n",
    "groupby_col = index_name\n",
    "aggregations = {\n",
    "             'price': ['mean','max','min'],\n",
    "             'mean_sq_spalen': ['mean','max','min'],\n",
    "             'mean_sq*price': ['mean']\n",
    "        }\n",
    "df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "df.drop(index_name, inplace=True, axis=1)\n",
    "\n",
    "df['AGG_price_MAX'] = df['AGG_price_MAX'].fillna(df['price'])\n",
    "df['AGG_price_MIN'] = df['AGG_price_MIN'].fillna(df['price'])\n",
    "df['AGG_price_MEAN'] = df['AGG_price_MEAN'].fillna(df['price'])\n",
    "df['AGG_mean_sq_spalen_MIN'] = df['AGG_mean_sq_spalen_MIN'].fillna(df['mean_sq_spalen'])\n",
    "df['AGG_mean_sq_spalen_MAX'] = df['AGG_mean_sq_spalen_MAX'].fillna(df['mean_sq_spalen'])\n",
    "df['AGG_mean_sq_spalen_MEAN'] = df['AGG_mean_sq_spalen_MEAN'].fillna(df['mean_sq_spalen'])\n",
    "df['AGG_mean_sq*price_MEAN'] = df['AGG_mean_sq*price_MEAN'].fillna(df['mean_sq*price'])\n",
    "\n",
    "df['price_diff_1'] = df['price']/df['AGG_price_MAX']\n",
    "df['price_diff_2'] = df['price']/df['AGG_price_MIN']\n",
    "df['price_diff_3'] = df['price']/df['AGG_price_MEAN']\n",
    "\n",
    "    ## 223\n",
    "\n",
    "col2 = 'spalen'\n",
    "col3 = 'month'\n",
    "index_name = 'index_'+'_'+col2+'_'+col3\n",
    "df[index_name] = df[col2].astype(str) + '-' + df[col3].astype(str)\n",
    "groupby_col = index_name\n",
    "aggregations = {\n",
    "                 'price': ['mean'],\n",
    "                 'mean_sq_spalen':  ['mean','max','min', 'var'],\n",
    "             }\n",
    "df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "df_agg.columns = pd.Index(['AGG_'+index_name + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "df.drop(index_name, inplace=True, axis=1)\n",
    "    \n",
    "groupby_col = 'bulk_id'\n",
    "aggregations = {\n",
    "                 'month_cnt': ['min'],\n",
    "             }\n",
    "df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "df_agg.columns = pd.Index(['AGG_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "df['AGG_month_cnt_MIN'] = df['AGG_month_cnt_MIN'].fillna(df['month_cnt'])\n",
    "df['flag_sales_started'] = np.where(df['month_cnt']==df['AGG_month_cnt_MIN'], 1, 0)\n",
    "df['sales_month_cnt'] =  df['month_cnt'] - df['AGG_month_cnt_MIN']\n",
    "\n",
    "groupby_col = 'month'\n",
    "aggregations = {}\n",
    "cols = ['mean_sq*price',\n",
    "        'mean_sq',\n",
    "#         'Машиномест'\n",
    "       ]\n",
    "for col in cols:\n",
    "    aggregations = {\n",
    "            col: ['min', 'max', 'mean'],\n",
    "        }\n",
    "df_agg = df.groupby([groupby_col]).agg(aggregations)\n",
    "df_agg.columns = pd.Index(['AGG_'+groupby_col+ e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "\n",
    "# temp, new_cols = add_lags(df, feat='value', index='new_index_spalen', by_col='month_cnt')\n",
    "# df = df.merge(temp[new_cols], on='new_index_spalen',  how='left')\n",
    "    \n",
    "temp, new_cols = add_lags(df, feat='price', index='new_index_spalen', by_col='month_cnt')\n",
    "df = df.merge(temp[new_cols], on='new_index_spalen',  how='left')\n",
    "    \n",
    "temp, new_cols = add_lags(df, feat='mean_sq', index='new_index_spalen', by_col='month_cnt')\n",
    "df = df.merge(temp[new_cols], on='new_index_spalen',  how='left')\n",
    "\n",
    "groupby_col = 'spalen'\n",
    "aggregations = {\n",
    "            'value': ['mean'],\n",
    "        }\n",
    "df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "df_agg.columns = pd.Index(['AGG_'+groupby_col+ e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "\n",
    "\n",
    "##### 199\n",
    "df['Курс_ratio'] = df['Курс']/np.min(df['Курс'])\n",
    "\n",
    "flats = get_flats(df)\n",
    "flats_cols = list(flats.columns)\n",
    "print(\"Flats df shape:\", flats.shape)\n",
    "df = df.join(flats, how='left', on='new_index_spalen')\n",
    "del flats\n",
    "gc.collect()\n",
    "\n",
    "# df_bulk_cols = ['bulk_id_1','bulk_id_2','bulk_id_3','bulk_id_4','bulk_id_5']\n",
    "# df_bulk = pd.DataFrame(df.bulk_id.str.split('-').values.tolist(), columns=df_bulk_cols\n",
    "#                        , index=df.index)\n",
    "# df[df_bulk_cols] = df_bulk[df_bulk_cols]\n",
    "# df.drop(['bulk_id_1','bulk_id_2','bulk_id_3','bulk_id_4'], inplace=True, axis=1)\n",
    "\n",
    "# col2 = 'spalen'\n",
    "# col3 = 'bulk_id_5'\n",
    "# index_name = 'index_'+col2+'_'+col3\n",
    "# df[index_name] = df[col2].astype(str) + '-' + df[col3].astype(str)\n",
    "# groupby_col = index_name\n",
    "# aggregations = {\n",
    "#                  'price': ['mean','max','min', 'var'],\n",
    "# #                  'value':  ['mean','max','min', 'var'],\n",
    "#                  'mean_sq_spalen': ['mean','max','min']\n",
    "#              }\n",
    "# df_agg = df[df.value > 0].groupby([groupby_col]).agg(aggregations)\n",
    "# df_agg.columns = pd.Index(['AGG_' + index_name + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "# df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "# df.drop(index_name, inplace=True, axis=1)\n",
    "\n",
    "# df['mean_sq_spalen_diff_1'] = df['price']/df['AGG_'+index_name+'mean_sq_spalen_MAX']\n",
    "# df['mean_sq_spalen_diff_2'] = df['price']/df['AGG_'+index_name+'mean_sq_spalen_MIN']\n",
    "# df['mean_sq_spalen_diff_3'] = df['price']/df['AGG_'+index_name+'mean_sq_spalen_MEAN']\n",
    "\n",
    "# col1 = 'Класс объекта'\n",
    "# col2 = 'spalen'\n",
    "# index_name = 'index_'+col1+'_'+col2\n",
    "# df[index_name] = df[col1] + '-' + df[col2].astype(str)\n",
    "# df_add[index_name] = df_add[col1] + '-' + df_add[col2].astype(str)\n",
    "# groupby_col = index_name\n",
    "# aggregations = {\n",
    "#              'start_square': ['mean','max','min','var'],\n",
    "#              'value': ['mean','max','min','var'],\n",
    "# #              'mean_sq_spalen': ['mean','max','min','var'],\n",
    "# #              'mean_sq': ['mean','max','min','var'],\n",
    "#         }\n",
    "\n",
    "# df_agg = df_add.groupby([groupby_col]).agg(aggregations)\n",
    "# df_agg.columns = pd.Index(['AGG_' + index_name + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "# df = df.join(df_agg, how='left', on=groupby_col, rsuffix='_'+groupby_col)\n",
    "# df.drop(index_name, inplace=True, axis=1)\n",
    "\n",
    "# df['ratio_mean_sq_1'] = df['AGG_'+index_name+'mean_sq_MEAN']/df['mean_sq']\n",
    "# df['ratio_mean_sq_2'] = df['AGG_'+index_name+'mean_sq_MAX']/df['mean_sq']\n",
    "# df['ratio_mean_sq_spalen_1'] = df['AGG_'+index_name+'mean_sq_MEAN']/df['mean_sq_spalen']\n",
    "# df['ratio_mean_sq_spalen_2'] = df['AGG_'+index_name+'mean_sq_MAX']/df['mean_sq_spalen']\n",
    "\n",
    "\n",
    "df['ratio_mean_sq_spalen'] = df['mean_sq_spalen']/df['AGG_mean_sq_spalen_MEAN']\n",
    "df['log_mean_sq*price'] = np.log1p(df['mean_sq*price'])\n",
    "df['log_price'] = np.log1p(df['price'])\n",
    "df['log_mean_sq'] = np.log1p(df['mean_sq'])\n",
    "# 198\n",
    "\n",
    "\n",
    "# df['ratio_mean_sq*price'] = df['mean_sq*price']/df['AGG_mean_sq*price_MEAN']\n",
    "# df['log_price-*-mean_sq*price'] = np.log1p(df['price-*-mean_sq*price'])\n",
    "# df['log_price-*-Станций метро от кольца*price'] = np.log1p(df['price-*-Станций метро от кольца*price']) \n",
    "# df['log_mean_sq*price-*-Станций метро от кольца*price']  = np.log1p(df['mean_sq*price-*-Станций метро от кольца*price']) \n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    if len(df[df[col].notnull()]) < len(df):\n",
    "#         print(col)\n",
    "        df[col] = df[col].fillna(df[df[col].notnull()][col].mean())\n",
    "\n",
    "cat_feats = ['spalen', 'month', 'Класс объекта',\n",
    "     'Огорожена территория', 'Входные группы', 'Детский сад', 'Школа',\n",
    "     'Поликлиника', 'ФОК', 'Спортивная площадка', 'Автомойка',\n",
    "     'Кладовые', 'Колясочные', 'Кондиционирование', 'Вентлияция',\n",
    "     'Лифт', 'Система мусоротведения', 'Видеонаблюдение', 'Подземная парковка',\n",
    "     'Двор без машин', 'flag_sales_started']\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in cat_feats:\n",
    "    df[col].fillna('Unknown')\n",
    "    df[col] = lbl.fit_transform(df[col].astype(str)) \n",
    "\n",
    "df.drop(['new_index_spalen'], axis=1, inplace=True)\n",
    "# df.drop(['date1'], axis=1, inplace=True)\n",
    "\n",
    "df[df.value == -1].to_csv(\"./input/test_.csv\", index=False)\n",
    "df[df.value > -1].to_csv(\"./input/train_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One left period validation\n",
    "\n",
    "df = pd.read_csv(\"./input/train_full.csv\")\n",
    "\n",
    "month_folds = ([30,31],[31,32]\n",
    "               ,[32,33],[33,34],[34,35],[35,36],[36,37])\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(month_folds):\n",
    "    train = df[df.month_cnt<train_index]\n",
    "    valid = df[df.month_cnt.between(train_index, valid_index)]\n",
    "\n",
    "    train.to_csv(f\"./input/train_month_folds_{i}.csv\",index=False)\n",
    "    valid.to_csv(f\"./input/valid_month_folds_{i}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=10, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "## KFold validation\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "K = 10\n",
    "df = pd.read_csv(\"./input/train_full.csv\")\n",
    "\n",
    "kf = KFold(n_splits=K, random_state=10, shuffle=True)\n",
    "kf.get_n_splits(range(len(df)))\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(range(len(df)))):\n",
    "    train = df.loc[train_index]\n",
    "    valid = df.loc[valid_index]\n",
    "\n",
    "    train.to_csv(f\"./input/train_{i}.csv\",index=False)\n",
    "    valid.to_csv(f\"./input/valid_{i}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8726 id\n",
      "1 233 bulk_id\n",
      "2 5 spalen\n",
      "3 31 date1\n",
      "4 4676 value\n",
      "5 7025 price\n",
      "6 3792 mean_sq\n",
      "7 32 mean_fl\n",
      "8 12 month\n",
      "9 31 month_cnt\n",
      "10 3 Класс объекта\n",
      "11 29 Количество помещений\n",
      "12 2 Огорожена территория\n",
      "13 29 Площадь земельного участка\n",
      "14 2 Входные группы\n",
      "15 21 Детский сад\n",
      "16 16 Школа\n",
      "17 4 Поликлиника\n",
      "18 2 ФОК\n",
      "19 1 Спортивная площадка\n",
      "20 2 Автомойка\n",
      "21 2 Кладовые\n",
      "22 2 Колясочные\n",
      "23 3 Кондиционирование\n",
      "24 3 Вентлияция\n",
      "25 1 Лифт\n",
      "26 1 Система мусоротведения\n",
      "27 3 Видеонаблюдение\n",
      "28 2 Подземная парковка\n",
      "29 2 Двор без машин\n",
      "30 29 Машиномест\n",
      "31 128 Площадь пром. зоны в радиусе 500 м\n",
      "32 173 Площадь зеленой зоны в радиусе 500 м\n",
      "33 17 До Кремля\n",
      "34 22 До ТТК(км)\n",
      "35 17 До Садового(км)\n",
      "36 105 До большой дороги на машине(км)\n",
      "37 79 До удобной авторазвязки на машине(км)\n",
      "38 81 До метро пешком(км)\n",
      "39 79 До промки(км)\n",
      "40 95 До парка(км)\n",
      "41 92 До парка пешком(км)\n",
      "42 10 Станций метро от кольца\n",
      "43 123 Площадь двора\n",
      "44 31 Курс\n",
      "45 30 Cтавка по ипотеке\n",
      "46 30 Вклады до 1 года\n",
      "47 31 Вклады от 1 года до 3 лет\n",
      "48 30 Вклады свыше 3 лет\n",
      "49 3072 mean_sq_spalen\n",
      "50 7594 mean_sq*price\n",
      "51 501 spalen*Площадь зеленой зоны в радиусе 500 м\n",
      "52 86 spalen*month_cnt\n",
      "53 5772 mean_sq*До удобной авторазвязки на машине(км)\n",
      "54 7303 Станций метро от кольца*price\n",
      "55 7596 price-*-mean_sq*price\n",
      "56 7369 price-*-Станций метро от кольца*price\n",
      "57 7596 mean_sq*price-*-Станций метро от кольца*price\n",
      "58 176 AGG_price_MEAN\n",
      "59 173 AGG_price_MAX\n",
      "60 168 AGG_price_MIN\n",
      "61 176 AGG_mean_sq_spalen_MEAN\n",
      "62 139 AGG_mean_sq_spalen_MAX\n",
      "63 128 AGG_mean_sq_spalen_MIN\n",
      "64 176 AGG_mean_sq*price_MEAN\n",
      "65 8475 price_diff_1\n",
      "66 8474 price_diff_2\n",
      "67 8655 price_diff_3\n",
      "68 60 AGG_index__spalen_monthprice_MEAN\n",
      "69 60 AGG_index__spalen_monthmean_sq_spalen_MEAN\n",
      "70 55 AGG_index__spalen_monthmean_sq_spalen_MAX\n",
      "71 44 AGG_index__spalen_monthmean_sq_spalen_MIN\n",
      "72 60 AGG_index__spalen_monthmean_sq_spalen_VAR\n",
      "73 30 AGG_month_cnt_MIN\n",
      "74 2 flag_sales_started\n",
      "75 50 sales_month_cnt\n",
      "76 4 AGG_monthmean_sq_MIN\n",
      "77 7 AGG_monthmean_sq_MAX\n",
      "78 12 AGG_monthmean_sq_MEAN\n",
      "79 738 price_lag_1\n",
      "80 688 mean_sq_lag_1\n",
      "81 5 AGG_spalenvalue_MEAN\n",
      "82 31 Курс_ratio\n",
      "83 20 FLATS_sp_stage_number_MAX\n",
      "84 489 FLATS_sp_stage_number_MEAN\n",
      "85 260 FLATS_sp_spalen_COUNT\n",
      "86 295 FLATS_sp_spalen_SUM\n",
      "87 711 FLATS_sp_square_SUM\n",
      "88 612 FLATS_sp_square_MEAN\n",
      "89 34 FLATS_sp_time_before_settle_MIN\n",
      "90 34 FLATS_sp_time_before_settle_MAX\n",
      "91 34 FLATS_sp_time_before_settle_MEAN\n",
      "92 7902 ratio_mean_sq_spalen\n",
      "93 7594 log_mean_sq*price\n",
      "94 7025 log_price\n",
      "95 3792 log_mean_sq\n",
      "96 8683 ratio_mean_sq*price\n",
      "97 7596 log_price-*-mean_sq*price\n",
      "98 7369 log_price-*-Станций метро от кольца*price\n",
      "99 7596 log_mean_sq*price-*-Станций метро от кольца*price\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for col in df.columns.tolist():\n",
    "    print(idx, len(df[col].unique()), col)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import create_cd\n",
    "\n",
    "create_cd(\n",
    "    label=4,\n",
    "    #cat_features=(2, 8, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 66),\n",
    "    cat_features=(2, 8, 10, 12, 14, 15, 16, 17, 18, 19,\n",
    "                  20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 42, 81),\n",
    "#     weight=1,\n",
    "#     baseline=2,\n",
    "    doc_id=0,\n",
    "    #group_id=1,\n",
    "#     subgroup_id=8,\n",
    "    auxiliary_columns=(1,3),\n",
    "    #timestamp=3,\n",
    "#     feature_names=feature_names,\n",
    "    output_path='./input/train2.cd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 started\n",
      "Iteration 0 with oof score 204.28098595455506\n",
      "Iteration 1 started\n",
      "Iteration 1 with oof score 247.42313728455727\n",
      "Iteration 2 started\n",
      "Iteration 2 with oof score 200.4002340728003\n",
      "Iteration 3 started\n",
      "Iteration 3 with oof score 192.50499913276875\n",
      "Iteration 4 started\n",
      "Iteration 4 with oof score 183.58216204713682\n",
      "Iteration 5 started\n",
      "Iteration 5 with oof score 201.41336909537418\n",
      "Iteration 6 started\n",
      "Iteration 6 with oof score 217.5833455423839\n",
      "Iteration 7 started\n",
      "Iteration 7 with oof score 214.14163122158908\n",
      "Iteration 8 started\n",
      "Iteration 8 with oof score 245.6235567309891\n",
      "Iteration 9 started\n",
      "Iteration 9 with oof score 222.06118148682836\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "K = 10\n",
    "\n",
    "path = './input/'\n",
    "\n",
    "TEST_FILE = path + 'test_.csv' #add\n",
    "CD_FILE = path + 'train2.cd'\n",
    "\n",
    "test_pool = Pool(TEST_FILE, column_description=CD_FILE, has_header=True, delimiter=\",\")\n",
    "df = pd.read_csv('./input/train_full.csv', encoding='cp1251')\n",
    "oof = np.zeros((len(df), 1))\n",
    "\n",
    "dt = pd.read_csv(TEST_FILE, encoding='cp1251')\n",
    "test = np.zeros((len(dt), 1))\n",
    "avg_score = 0\n",
    "\n",
    "for i in range(K):\n",
    "    print('Iteration {} started'.format(i))\n",
    "    TRAIN_FILE = path+f'train_{i}.csv'\n",
    "    VAL_FILE = path+f'valid_{i}.csv'\n",
    "\n",
    "    train_pool = Pool(TRAIN_FILE, column_description=CD_FILE, has_header=True, delimiter=\",\")\n",
    "    val_pool = Pool(VAL_FILE, column_description=CD_FILE, has_header=True, delimiter=\",\")\n",
    "\n",
    "    model = CatBoostRegressor(iterations=2000, \n",
    "                              learning_rate=0.2, \n",
    "                              depth=11, \n",
    "                              random_seed = 10,\n",
    "                              verbose = False\n",
    "                              )\n",
    "    \n",
    "    model.fit(train_pool, eval_set = val_pool)\n",
    "    \n",
    "    pred = model.predict(test_pool)\n",
    "    test += pred.reshape((len(dt),1))\n",
    "    dt['value'] = pred\n",
    "    dt.to_csv(f\"./output/test_{i}.csv\", index=False, columns=['id','value'])\n",
    "    \n",
    "    pred = model.predict(val_pool)\n",
    "    df = pd.read_csv(VAL_FILE)\n",
    "    oof[df.id] = pred.reshape((len(df),1))\n",
    "    df['value'] = pred\n",
    "    df.to_csv(f\"./output/oof_{i}.csv\", index=False, columns=['id','value'])\n",
    "\n",
    "    full_train_pool = Pool(TRAIN_FILE, column_description=CD_FILE, has_header=True, delimiter=\",\")\n",
    "    oof_value = pd.read_csv(VAL_FILE, encoding='cp1251')['value']\n",
    "    oof_score = model.score(val_pool, oof_value)\n",
    "    print('Iteration {} with oof score {}'.format(i, oof_score))\n",
    "    avg_score += oof_score\n",
    "    \n",
    "df = pd.read_csv(path+\"sample submission.csv\", encoding='cp1251')\n",
    "\n",
    "df['value'] = (test/K).clip(0, 5000)\n",
    "df.to_csv('submission_catboost_'+str(avg_score/(i+1))+'.csv', index=False)\n",
    "\n",
    "df = pd.read_csv(path+\"train_full.csv\", encoding='cp1251')\n",
    "df['value_pred'] = oof\n",
    "df.to_csv('./output/oof_'+str(avg_score/(i+1))+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lightgbm\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "iter_num = 0\n",
    "n_folds = 7\n",
    "avg_score = 0\n",
    "feature_importance_df = pd.DataFrame()\n",
    "df_train = pd.read_csv('./input/train_full.csv', encoding='cp1251')\n",
    "# df_train.to_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "# df_oof = np.zeros((len(df), n_folds))\n",
    "# df_meta = pd.read_csv('submission_catboost_211.43605189630915_199_05136.csv')\n",
    "df_test = pd.read_csv('./input/test_.csv')\n",
    "\n",
    "# df_test['metafeature_catboost'] = df_meta['value']\n",
    "test = np.zeros((len(df_test), 1))\n",
    "oof = np.zeros((len(df_train), 1))\n",
    "num_seeds = 1\n",
    "for s in range(num_seeds):\n",
    "    for fold in range(n_folds):\n",
    "        iter_num += 1\n",
    "        df_train = pd.read_csv('./input/train_month_folds_{}.csv'.format(fold))\n",
    "        df_valid = pd.read_csv('./input/valid_month_folds_{}.csv'.format(fold))\n",
    "        target_train = df_train.pop('value')\n",
    "        target_valid = df_valid.pop('value')\n",
    "\n",
    "        discard_feats = ['id','bulk_id','date1','bulk_id_5']\n",
    "\n",
    "        cat_feats = ['spalen', 'month', 'Класс объекта',\n",
    "         'Огорожена территория', 'Входные группы', 'Детский сад', 'Школа',\n",
    "         'Поликлиника', 'ФОК', 'Спортивная площадка', 'Автомойка',\n",
    "         'Кладовые', 'Колясочные', 'Кондиционирование', 'Вентлияция',\n",
    "         'Лифт', 'Система мусоротведения', 'Видеонаблюдение', 'Подземная парковка',\n",
    "         'Двор без машин', 'flag_sales_started']\n",
    "\n",
    "        feats = [f for f in df_train.columns.tolist() if f not in discard_feats]\n",
    "    #     feats = [f for f in feats if f not in cat_feats]\n",
    "\n",
    "        lgtrain = lgb.Dataset(df_train[feats], target_train,\n",
    "                            feature_name=feats,\n",
    "                            categorical_feature = cat_feats\n",
    "                             )\n",
    "        lgvalid = lgb.Dataset(df_valid[feats], target_valid,\n",
    "                            feature_name=feats,\n",
    "                            categorical_feature = cat_feats\n",
    "                             )\n",
    "\n",
    "        lgbm_params =  {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            # 'max_depth': 15,\n",
    "            'num_leaves': 34,\n",
    "            'nthread':4,\n",
    "            'learning_rate': 0.005,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'subsample': 0.87,\n",
    "            'max_depth': -1,\n",
    "            'reg_alpha': 0.04,\n",
    "            'min_split_gain': 0.017,\n",
    "            'min_child_weight': 20,\n",
    "            'verbose': -1,\n",
    "            'silent':-1,\n",
    "            'seed':s,\n",
    "            'random_state':s\n",
    "        }\n",
    "\n",
    "        lgb_clf = lgb.train(\n",
    "                lgbm_params,\n",
    "                lgtrain,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgtrain, lgvalid],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=300,\n",
    "                verbose_eval=10000\n",
    "            )\n",
    "        # print('RMSE:', np.sqrt(mean_squared_error(target_valid, lgb_clf.predict(df_valid[feats]))))\n",
    "        pred = lgb_clf.predict(df_test[feats])\n",
    "        test += pred.reshape((len(df_test),1))\n",
    "        df_test['value'] = pred\n",
    "        df_test.to_csv(\"./output/test_lgbm_m_{}.csv.\".format(fold), index=False, columns=['id','value'])\n",
    "        pred = lgb_clf.predict(df_valid[feats])\n",
    "        df = pd.read_csv(\"./input/valid_month_folds_{}.csv.\".format(fold))\n",
    "        oof[df.id] = pred.reshape((len(df),1))\n",
    "        df['value'] = pred\n",
    "        df.to_csv(\"./output/oof_lgbm_m_{}.csv\".format(fold), index=False, columns=['id','value'])\n",
    "    #     full_train = pd.read_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "    #     full_train['oof_'.format(fold)] = pred\n",
    "    #     full_train.to_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "    #     oof_score = model.score(val_pool, oof_value)\n",
    "    #     print('Iteration {} with oof score {}'.format(i, oof_score))\n",
    "        oof_score = mean_squared_error(target_valid, pred)**0.5\n",
    "        avg_score += oof_score\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_clf.feature_importance\n",
    "        fold_importance_df[\"fold\"] = fold + 1\n",
    "        fold_importance_df[\"seed\"] = s\n",
    "        fold_importance_df['oof_score'] = oof_score\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "df = pd.read_csv('./input/sample submission.csv', encoding='cp1251')\n",
    "\n",
    "df['value'] = (test/iter_num).clip(0, 3000)\n",
    "df.to_csv('submission_lgbm_m_'+str(avg_score/(iter_num))+'.csv', index=False)\n",
    "print('Score {}'.format(avg_score/iter_num))\n",
    "# df = pd.read_csv(path+\"train_full.csv\", encoding='cp1251')\n",
    "# df['value_pred'] = oof\n",
    "# df.to_csv('./output/oof_'+str(avg_score/(i+1))+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding metafeatures and starting lgbm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "df_stack_meta1 = pd.DataFrame()\n",
    "df_stack_meta2 = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    df = pd.read_csv('./output/oof_{}.csv'.format(i))\n",
    "    val = df['value']\n",
    "    df_stack_meta1 = pd.concat([df_stack_meta1, df])\n",
    "\n",
    "    df = pd.read_csv('./output/oof_lgbm_{}.csv'.format(i))\n",
    "    val = df['value']\n",
    "    df_stack_meta2 = pd.concat([df_stack_meta2, df])\n",
    "df_stack_meta1 = df_stack_meta1.sort_values(['id']).set_index(['id'])\n",
    "df_stack_meta2 = df_stack_meta2.sort_values(['id']).set_index(['id'])\n",
    "\n",
    "K = 10\n",
    "df = pd.read_csv(\"./input/train_full.csv\")\n",
    "df['metafeature_catboost'] = df_stack_meta1['value']\n",
    "df['metafeature_lgbm'] = df_stack_meta2['value']\n",
    "\n",
    "df_test = pd.read_csv('./input/test_.csv')\n",
    "df_stack_meta1 = pd.read_csv('submission_catboost_212.64175801420384_198.csv')\n",
    "df_stack_meta2 = pd.read_csv('submission_lgbm_207.2784140815164_205_224.csv')\n",
    "df_test['metafeature_catboost'] = df_stack_meta1['value']\n",
    "df_test['metafeature_lgbm'] = df_stack_meta2['value']\n",
    "\n",
    "kf = KFold(n_splits=K, random_state=100, shuffle=True)\n",
    "kf.get_n_splits(range(len(df)))\n",
    "\n",
    "print(kf)  \n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(range(len(df)))):\n",
    "    train = df.loc[train_index]\n",
    "    valid = df.loc[valid_index]\n",
    "\n",
    "    train.to_csv(f\"./input/train_meta_cb_{i}.csv\",index=False)\n",
    "    valid.to_csv(f\"./input/valid_meta_cb_{i}.csv\",index=False)\n",
    "\n",
    "df_test.to_csv('./input/test_meta.csv',index=False)\n",
    "    \n",
    "iter_num = 0\n",
    "n_folds = 10\n",
    "avg_score = 0\n",
    "feature_importance_df = pd.DataFrame()\n",
    "df_train = pd.read_csv('./input/train_full.csv', encoding='cp1251')\n",
    "# df_train.to_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "# df_oof = np.zeros((len(df), n_folds))\n",
    "# df_meta = pd.read_csv('submission_catboost_211.43605189630915_199_05136.csv')\n",
    "# df_test = pd.read_csv('./input/test_.csv')\n",
    "\n",
    "# df_test['metafeature_catboost'] = df_meta['value']\n",
    "test = np.zeros((len(df_test), 1))\n",
    "oof = np.zeros((len(df_train), 1))\n",
    "num_seeds = 1\n",
    "for s in range(num_seeds):\n",
    "    for fold in range(n_folds):\n",
    "        iter_num += 1\n",
    "        df_train = pd.read_csv('./input/train_meta_cb_{}.csv'.format(fold))\n",
    "        df_valid = pd.read_csv('./input/valid_meta_cb_{}.csv'.format(fold))\n",
    "        target_train = df_train.pop('value')\n",
    "        target_valid = df_valid.pop('value')\n",
    "\n",
    "        discard_feats = ['id','bulk_id','date1','bulk_id_5']\n",
    "\n",
    "        cat_feats = ['spalen', 'month', 'Класс объекта',\n",
    "         'Огорожена территория', 'Входные группы', 'Детский сад', 'Школа',\n",
    "         'Поликлиника', 'ФОК', 'Спортивная площадка', 'Автомойка',\n",
    "         'Кладовые', 'Колясочные', 'Кондиционирование', 'Вентлияция',\n",
    "         'Лифт', 'Система мусоротведения', 'Видеонаблюдение', 'Подземная парковка',\n",
    "         'Двор без машин', 'flag_sales_started']\n",
    "\n",
    "        feats = [f for f in df_train.columns.tolist() if f not in discard_feats]\n",
    "#         feats = ['metafeature_catboost','metafeature_lgbm']\n",
    "\n",
    "        lgtrain = lgb.Dataset(df_train[feats], target_train,\n",
    "                            feature_name=feats,\n",
    "                            categorical_feature = cat_feats\n",
    "                             )\n",
    "        lgvalid = lgb.Dataset(df_valid[feats], target_valid,\n",
    "                            feature_name=feats,\n",
    "                            categorical_feature = cat_feats\n",
    "                             )\n",
    "\n",
    "        lgbm_params =  {\n",
    "            'task': 'train',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            # 'max_depth': 15,\n",
    "            'num_leaves': 34,\n",
    "            'nthread':4,\n",
    "            'learning_rate': 0.01,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'subsample': 0.87,\n",
    "            'max_depth': -1,\n",
    "            'reg_alpha': 0.04,\n",
    "            'min_split_gain': 0.017,\n",
    "            'min_child_weight': 20,\n",
    "            'verbose': -1,\n",
    "            'silent':-1,\n",
    "            'seed':s,\n",
    "            'random_state':s\n",
    "        }\n",
    "\n",
    "        lgb_clf = lgb.train(\n",
    "                lgbm_params,\n",
    "                lgtrain,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgtrain, lgvalid],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=300,\n",
    "                verbose_eval=10000\n",
    "            )\n",
    "        # print('RMSE:', np.sqrt(mean_squared_error(target_valid, lgb_clf.predict(df_valid[feats]))))\n",
    "        pred = lgb_clf.predict(df_test[feats])\n",
    "        test += pred.reshape((len(df_test),1))\n",
    "        df_test['value'] = pred\n",
    "#         df_test.to_csv(\"./output/test_lgbm_{}.csv.\".format(fold), index=False, columns=['id','value'])\n",
    "        pred = lgb_clf.predict(df_valid[feats])\n",
    "        df = pd.read_csv(\"./output/oof_{}.csv.\".format(fold))\n",
    "        oof[df.id] = pred.reshape((len(df),1))\n",
    "        df['value'] = pred\n",
    "#         df.to_csv(\"./output/oof_lgbm_{}.csv\".format(fold), index=False, columns=['id','value'])\n",
    "    #     full_train = pd.read_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "    #     full_train['oof_'.format(fold)] = pred\n",
    "    #     full_train.to_csv('./input/train_full_lgbm.csv', encoding='cp1251')\n",
    "    #     oof_score = model.score(val_pool, oof_value)\n",
    "    #     print('Iteration {} with oof score {}'.format(i, oof_score))\n",
    "        oof_score = mean_squared_error(target_valid, pred)**0.5\n",
    "        avg_score += oof_score\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_clf.feature_importance\n",
    "        fold_importance_df[\"fold\"] = fold + 1\n",
    "        fold_importance_df[\"seed\"] = s\n",
    "        fold_importance_df['oof_score'] = oof_score\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "df = pd.read_csv('./input/sample submission.csv', encoding='cp1251')\n",
    "\n",
    "df['value'] = (test/iter_num).clip(0, 3000)\n",
    "df.to_csv('submission_lgbm_meta_'+str(avg_score/(iter_num))+'.csv', index=False)\n",
    "print('Score {}'.format(avg_score/iter_num))\n",
    "# df = pd.read_csv(path+\"train_full.csv\", encoding='cp1251')\n",
    "# df['value_pred'] = oof\n",
    "# df.to_csv('./output/oof_'+str(avg_score/(i+1))+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
